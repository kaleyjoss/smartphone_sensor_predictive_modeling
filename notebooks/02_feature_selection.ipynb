{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature creation and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/b24z_8kn4490x_bl0njv6fg00000gn/T/ipykernel_7846/2386633691.py:28: DtypeWarning: Columns (14,23,48,106,107,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_alldays_int70 = pd.read_csv(os.path.join(brighten_dir, 'df_alldays_int70.csv'))\n",
      "/var/folders/fl/b24z_8kn4490x_bl0njv6fg00000gn/T/ipykernel_7846/2386633691.py:30: DtypeWarning: Columns (24,107,108,109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  week_df_int70 = pd.read_csv(os.path.join(brighten_dir, 'week_df_int70.csv'))\n"
     ]
    }
   ],
   "source": [
    "######################## LOAD IN FILES #############################\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# Define data directory\n",
    "brighten_dir = os.path.join(project_root, 'BRIGHTEN_data')\n",
    "\n",
    "# Add project root to sys.path for script usage\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import and reload (optional) custom scripts\n",
    "# Import and reload custom scripts\n",
    "from scripts import preprocessing as pre\n",
    "from scripts import visualization as vis\n",
    "from scripts import feature_selection as fs\n",
    "from scripts import clustering as cl\n",
    "from scripts import variables as var\n",
    "importlib.reload(pre)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(fs)\n",
    "importlib.reload(cl)\n",
    "importlib.reload(var)\n",
    "\n",
    "df_alldays_int70 = pd.read_csv(os.path.join(brighten_dir, 'df_alldays_int70.csv'))\n",
    "df_alldays_int70['dt'] = pd.to_datetime(df_alldays_int70['dt'], errors='coerce')\n",
    "week_df_int70 = pd.read_csv(os.path.join(brighten_dir, 'week_df_int70.csv'))\n",
    "\n",
    "############ LOAD in PACKAGES  #############\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "################ DEFINE column variables from data ###################\n",
    "from scripts.variables import id_columns, daily_cols_v1, daily_v2_common \n",
    "from scripts.variables import phq2_cols, phq9_cols, weekly_cols, passive_cols, survey_cols\n",
    "from scripts.variables import df_names, df_names_with_mis\n",
    "\n",
    "\n",
    "## Create wide versions of each vars list\n",
    "wide_v1_cols = []\n",
    "for var in daily_cols_v1:\n",
    "    wide_v1_cols.append(f'{var}_avg_w1')\n",
    "    wide_v1_cols.append(f'{var}_avg_w2')\n",
    "    wide_v1_cols.append(f'{var}_slope_w2')\n",
    "    wide_v1_cols.append(f'{var}_avg_w4')\n",
    "    wide_v1_cols.append(f'{var}_slope_w4')\n",
    "\n",
    "wide_v2_cols = []\n",
    "for var in daily_v2_common:\n",
    "    wide_v2_cols.append(f'{var}_avg_w1')\n",
    "    wide_v2_cols.append(f'{var}_avg_w2')\n",
    "    wide_v2_cols.append(f'{var}_slope_w2')\n",
    "    wide_v2_cols.append(f'{var}_avg_w4')\n",
    "    wide_v2_cols.append(f'{var}_slope_w4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_dfs_clusters = {}\n",
    "for name in df_names_with_mis:\n",
    "    wide_dfs_clusters[name] = pd.read_csv(os.path.join(brighten_dir, f'wide_{name}_clusters.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wide_dfs_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VarianceThreshold\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define feature and target columns\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwide_dfs_clusters\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1_day\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepression\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphq2\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m id_columns]\n\u001b[1;32m      5\u001b[0m y_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphq2_bin_avg_w4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create DataFrame with relevant columns\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wide_dfs_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Define feature and target columns\n",
    "X_cols = [col for col in wide_dfs_clusters['v1_day'] if 'depression' not in col and 'phq2' not in col and col not in id_columns]\n",
    "y_col = 'phq2_bin_avg_w4'\n",
    "\n",
    "# Create DataFrame with relevant columns\n",
    "lr_df = wide_dfs_clusters['v1_day'][['num_id', y_col] + X_cols]\n",
    "\n",
    "# Display feature variances\n",
    "feature_variances = lr_df[X_cols].var()\n",
    "print(feature_variances.sort_values())  # See how much variance your features have\n",
    "\n",
    "# Display correlation matrix\n",
    "corr_matrix = lr_df[X_cols + [y_col]].corr().abs()\n",
    "# print(corr_matrix[y_col])\n",
    "\n",
    "\n",
    "# Apply Variance Threshold to drop low-variance features\n",
    "selector = VarianceThreshold(threshold=0.005)  # Adjust as needed\n",
    "X_selected = selector.fit_transform(lr_df[X_cols])  # Returns a NumPy array\n",
    "\n",
    "# Get names of selected columns\n",
    "selected_columns = [X_cols[i] for i in range(len(X_cols)) if selector.get_support()[i]]\n",
    "dropped_columns = list(set(X_cols) - set(selected_columns))\n",
    "\n",
    "print(f\"Dropped low-variance features: {dropped_columns}\")\n",
    "\n",
    "# Convert selected features back to DataFrame for correlation analysis\n",
    "X_filtered = pd.DataFrame(X_selected, columns=selected_columns)\n",
    "\n",
    "# Compute correlation matrix (absolute values)\n",
    "corr_matrix = X_filtered.corr().abs()\n",
    "print(corr_matrix[y_col])\n",
    "\n",
    "# Zero out the diagonal (self-correlation)\n",
    "np.fill_diagonal(corr_matrix.values, 0)\n",
    "corr_matrix.to_csv(os.path.join(brighten_dir, 'wide_v1Day_highVar_corrMatrix.csv'))\n",
    "\n",
    "# Define threshold for high correlation (e.g., 0.9)\n",
    "threshold = 0.9\n",
    "\n",
    "# Get correlation of features with target variable\n",
    "target_corr = corr_matrix[y_col].sort_values(ascending=False)\n",
    "\n",
    "# Identify highly correlated feature pairs\n",
    "to_drop = set()\n",
    "for col in corr_matrix.columns:\n",
    "    if col == y_col:  \n",
    "        continue  # Skip target variable\n",
    "    \n",
    "    # Find features highly correlated with the current feature\n",
    "    high_corr_features = corr_matrix.index[(corr_matrix[col] > threshold)].tolist()\n",
    "    \n",
    "    # Remove features but keep the one most correlated with the target\n",
    "    high_corr_features.remove(col)  # Keep the current feature\n",
    "    for feature in high_corr_features:\n",
    "        if target_corr[col] >= target_corr[feature]:  # Keep the stronger predictor\n",
    "            to_drop.add(feature)\n",
    "        else:\n",
    "            to_drop.add(col)\n",
    "\n",
    "# Drop selected features\n",
    "df_selected = X_filtered.drop(columns=to_drop)\n",
    "\n",
    "print(f\"Dropped {len(to_drop)} highly correlated features: {to_drop}\")\n",
    "\n",
    "display(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is shape (57, 102)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m rlr_df[y_col]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Apply Randomized Logistic Regression\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m selected_features, feature_importances \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandomized_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Print selected feature indices\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected Features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/Box-Box/Holmes_lab_kaley/motif_proj/smartphone_sensor_predictive_modeling/scripts/feature_selection.py:65\u001b[0m, in \u001b[0;36mrandomized_logistic_regression\u001b[0;34m(X, y, num_samples, selection_threshold)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Fit L1-penalized Logistic Regression\u001b[39;00m\n\u001b[1;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Store the absolute coefficients\u001b[39;00m\n\u001b[1;32m     68\u001b[0m coef_matrix[i, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(model\u001b[38;5;241m.\u001b[39mcoef_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1276\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1272\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1273\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1274\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[1;32m   1275\u001b[0m         )\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1229\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1226\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1228\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[0;32m-> 1229\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m n_iter_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PHQ9 Cat, phq9 cat change\n",
    "\n",
    "print(f'df is shape {lr_df.shape}')\n",
    "\n",
    "X_scaled = lr_df[X_cols].copy()\n",
    "y = lr_df[y_col].copy()\n",
    "\n",
    "# Apply Randomized Logistic Regression\n",
    "selected_features, feature_importances = fs.randomized_logistic_regression(X_scaled, y)\n",
    "\n",
    "# Print selected feature indices\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "print(f\"Feature Importances: {feature_importances}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['aggregate_communication_avg_w2', 'aggregate_communication_slope_w2', 'aggregate_communication_slope_w4', 'call_count_avg_w2', 'call_count_slope_w2', 'call_count_slope_w4', 'call_duration_avg_w2', 'call_duration_slope_w2', 'call_duration_slope_w4', 'interaction_diversity_avg_w2', 'interaction_diversity_slope_w2', 'interaction_diversity_slope_w4', 'missed_interactions_avg_w2', 'missed_interactions_slope_w2', 'missed_interactions_slope_w4', 'mobility_avg_w2', 'mobility_slope_w2', 'mobility_slope_w4', 'mobility_radius_avg_w2', 'mobility_radius_slope_w2', 'mobility_radius_slope_w4', 'sms_count_avg_w2', 'sms_count_slope_w2', 'sms_count_slope_w4', 'sms_length_avg_w2', 'sms_length_slope_w2', 'sms_length_slope_w4', 'unreturned_calls_avg_w2', 'unreturned_calls_slope_w2', 'unreturned_calls_slope_w4'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphq9_bin_avg_w4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m X_cols \u001b[38;5;241m=\u001b[39m wide_v1_cols\n\u001b[0;32m----> 5\u001b[0m rlr_df \u001b[38;5;241m=\u001b[39m \u001b[43mwide_dfs_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv1_week\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m rlr_df \u001b[38;5;241m=\u001b[39m rlr_df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf is shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrlr_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['aggregate_communication_avg_w2', 'aggregate_communication_slope_w2', 'aggregate_communication_slope_w4', 'call_count_avg_w2', 'call_count_slope_w2', 'call_count_slope_w4', 'call_duration_avg_w2', 'call_duration_slope_w2', 'call_duration_slope_w4', 'interaction_diversity_avg_w2', 'interaction_diversity_slope_w2', 'interaction_diversity_slope_w4', 'missed_interactions_avg_w2', 'missed_interactions_slope_w2', 'missed_interactions_slope_w4', 'mobility_avg_w2', 'mobility_slope_w2', 'mobility_slope_w4', 'mobility_radius_avg_w2', 'mobility_radius_slope_w2', 'mobility_radius_slope_w4', 'sms_count_avg_w2', 'sms_count_slope_w2', 'sms_count_slope_w4', 'sms_length_avg_w2', 'sms_length_slope_w2', 'sms_length_slope_w4', 'unreturned_calls_avg_w2', 'unreturned_calls_slope_w2', 'unreturned_calls_slope_w4'] not in index\""
     ]
    }
   ],
   "source": [
    "# PHQ9 Cat, phq9 cat change\n",
    "\n",
    "y_cols = 'phq9_bin_avg_w4'\n",
    "X_cols = [col for col in wide_dfs_clusters['v1_week'] if 'depression' not in col and 'phq2' not in col and 'phq9' not in col and col not in id_columns]\n",
    "rlr_df = wide_dfs_clusters['v1_week'][['num_id', y_cols] + X_cols]\n",
    "rlr_df = rlr_df.dropna()\n",
    "print(f'df is shape {rlr_df.shape}')\n",
    "\n",
    "X_scaled = rlr_df[X_cols].copy()\n",
    "y = rlr_df[y_cols].copy()\n",
    "\n",
    "# Apply Randomized Logistic Regression\n",
    "selected_features, feature_importances = fs.randomized_logistic_regression(X_scaled, y)\n",
    "\n",
    "# Print selected feature indices\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "print(f\"Feature Importances: {feature_importances}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
