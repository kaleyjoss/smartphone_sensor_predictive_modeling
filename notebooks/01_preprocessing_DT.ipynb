{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature creation and translation to wide df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/b24z_8kn4490x_bl0njv6fg00000gn/T/ipykernel_33337/514711111.py:34: DtypeWarning: Columns (14,23,48,106,107,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_alldays_int70 = pd.read_csv(os.path.join(brighten_dir, 'df_alldays_int70.csv'))\n",
      "/var/folders/fl/b24z_8kn4490x_bl0njv6fg00000gn/T/ipykernel_33337/514711111.py:35: DtypeWarning: Columns (24,107,108,109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  week_df_int70 = pd.read_csv(os.path.join(brighten_dir, 'week_df_int70.csv'))\n"
     ]
    }
   ],
   "source": [
    "######################## LOAD IN FILES #############################\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# Define data directory\n",
    "brighten_dir = os.path.join(project_root, 'BRIGHTEN_data')\n",
    "\n",
    "# Add project root to sys.path for script usage\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import and reload (optional) custom scripts\n",
    "# Import and reload custom scripts\n",
    "from scripts import preprocessing as pre\n",
    "from scripts import visualization as vis\n",
    "from scripts import feature_selection as fs\n",
    "from scripts import clustering as cl\n",
    "from scripts import variables as var\n",
    "importlib.reload(pre)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(fs)\n",
    "importlib.reload(cl)\n",
    "importlib.reload(var)\n",
    "\n",
    "################ DEFINE column variables from data ###################\n",
    "from scripts.variables import id_columns, daily_cols_v1, daily_v2_common \n",
    "from scripts.variables import phq2_cols, phq9_cols, weekly_cols, passive_cols, survey_cols\n",
    "from scripts.variables import df_names, df_names_with_mis\n",
    "\n",
    "############ Import compiled raw data ############\n",
    "df_alldays_int70 = pd.read_csv(os.path.join(brighten_dir, 'df_alldays_int70.csv'))\n",
    "week_df_int70 = pd.read_csv(os.path.join(brighten_dir, 'week_df_int70.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/b24z_8kn4490x_bl0njv6fg00000gn/T/ipykernel_33337/336776481.py:14: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  df_bin = df.merge(df_alldays_int70[id_columns + merge_cols], on=id_columns, how='left')\n",
      "/var/folders/fl/b24z_8kn4490x_bl0njv6fg00000gn/T/ipykernel_33337/336776481.py:14: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  df_bin = df.merge(df_alldays_int70[id_columns + merge_cols], on=id_columns, how='left')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name in df_names_with_mis:\n",
    "    if os.path.exists(os.path.join(brighten_dir, f'{name}_pca.csv')):\n",
    "        df = pd.read_csv(os.path.join(brighten_dir, f'{name}_pca.csv'))\n",
    "    else:\n",
    "        df = pd.read_csv(os.path.join(brighten_dir, f'{name}_scaled.csv'))\n",
    "    if 'day' in name:\n",
    "        if 'phq2_bin' not in df.columns.to_list():\n",
    "            df_bin = df.merge(df_alldays_int70[id_columns + ['phq2_bin']], on=id_columns, how='left')\n",
    "        else:\n",
    "            df_bin = df\n",
    "    elif 'week' in name:\n",
    "        merge_cols = [col for col in ['phq2_bin', 'phq9_bin', 'phq9_cat'] if col not in df.columns.to_list()]\n",
    "        if len(merge_cols) > 0:\n",
    "            df_bin = df.merge(df_alldays_int70[id_columns + merge_cols], on=id_columns, how='left')\n",
    "        else:\n",
    "            df_bin = bin\n",
    "\n",
    "    df_bin.to_csv(os.path.join(brighten_dir, f'{name}_bin.csv'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making features -- averaging of time data\n",
    "\n",
    "for name in df_names_with_mis:\n",
    "    df_bin = pd.read_csv(os.path.join(brighten_dir, f'{name}_bin.csv'))\n",
    "    wide_df_bin = pre.make_wide_df(df_bin, id_columns)\n",
    "    wide_df_bin.to_csv(os.path.join(brighten_dir, f'wide_{name}_bin.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in df_names_with_mis:\n",
    "    wide_df_bin = pd.read_csv(os.path.join(brighten_dir, f'wide_{name}_bin.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add binary\n",
    "for name in df_names_with_mis:\n",
    "    df_pca_bin = pd.read_csv(os.path.join(brighten_dir, f'wide_{name}_bin.csv'))\n",
    "    if 'day' in name:\n",
    "        df_pca_bin_day = pre.round_vars_phq2(df_pca_bin)\n",
    "        df_pca_bin_day = df_pca_bin_day.dropna()\n",
    "        df_pca_bin_day.to_csv(os.path.join(brighten_dir, f'{name}_bin.csv'))\n",
    "    if 'week' in name:\n",
    "        df_pca_bin_week = pre.round_vars_phq9(df_pca_bin)\n",
    "        df_pca_bin_week.to_csv(os.path.join(brighten_dir, f'{name}_bin.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_clusters = pd.read_csv(os.path.join(brighten_dir, 'demo_clusters.csv'))\n",
    "# Merge in demographic clusters\n",
    "for name in df_names_with_mis:\n",
    "    df_bin = pd.read_csv(os.path.join(brighten_dir, f'{name}_bin.csv'))\n",
    "    df_clusters = df_bin.merge(demo_clusters[['participant_id', 'Cluster']], on=['participant_id'], how='left')\n",
    "    df_clusters_merged = df_clusters.merge(df_alldays_int70[['participant_id']], on=['participant_id'], how='left')\n",
    "    df_clusters = df_clusters_merged.drop_duplicates().dropna()\n",
    "    df_clusters = df_clusters.drop(columns=[col for col in df.columns if \"Unnamed\" in col or \"0\" in col])\n",
    "    #print(df_clusters.columns.to_list())\n",
    "    df_clusters.to_csv(os.path.join(brighten_dir, f'wide_{name}_clusters.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
