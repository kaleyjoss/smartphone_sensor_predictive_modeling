{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_dir = '/Users/demo/Library/CloudStorage/Box-Box/Holmes_lab_kaley/motif_proj'\n",
    "brighten_dir = os.path.join(project_dir, 'BRIGHTEN_data')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dfs_lagged = {}\n",
    "dfs_lagged['v1_day'] = pd.read_csv(os.path.join(brighten_dir, 'v1_day_lag.csv'))\n",
    "dfs_lagged['v1_week_phq9'] = pd.read_csv(os.path.join(brighten_dir, 'v1_week_phq9_lag.csv'))\n",
    "dfs_lagged['v2_day'] = pd.read_csv(os.path.join(brighten_dir, 'v2_day_lag.csv'))\n",
    "dfs_lagged['v2_week_phq9'] = pd.read_csv(os.path.join(brighten_dir, 'v2_week_phq9_lag.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_largest_continuous_sequence(df, time_period, sequence_length=6):\n",
    "    \"\"\"\n",
    "    Finds the largest continuous sequence in the time_period column of a DataFrame.\n",
    "    Returns a subset of the DataFrame for the specified sequence length.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by time_period\n",
    "    df = df.sort_values(by=time_period).reset_index(drop=True)\n",
    "\n",
    "    # Calculate differences and group continuous sequences\n",
    "    diff = df[time_period].diff().ne(1).cumsum()\n",
    "    sequences = df.groupby(diff)[time_period].agg(['min', 'max', 'size'])\n",
    "\n",
    "    # Find the largest sequence\n",
    "    largest_sequence = sequences.loc[sequences['size'].idxmax()]\n",
    "\n",
    "    # Check if the largest sequence meets the minimum size requirement\n",
    "    if largest_sequence['size'] >= sequence_length:\n",
    "        idx_seq_min = largest_sequence['min']\n",
    "        idx_seq_max = idx_seq_min + sequence_length - 1  # Inclusive range\n",
    "        return df[(df[time_period] >= idx_seq_min) & (df[time_period] <= idx_seq_max)]\n",
    "    else:\n",
    "        return None  # Return None if no sequence meets the condition\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prep for mmelsm \n",
    "df_mmelsm = {}\n",
    "\n",
    "# V2_Day\n",
    "v2_day_mmelsm = []\n",
    "sequence_length = 6 \n",
    "time_period = 'day'\n",
    "\n",
    "for participant, df in dfs_lagged['v2_day_lag'].groupby('participant_id'):\n",
    "    result = find_largest_continuous_sequence(df, time_period, sequence_length)\n",
    "    if result is not None:\n",
    "        v2_day_mmelsm.append(result)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if v2_day_mmelsm:\n",
    "    v2_day_mmelsm = pd.concat(v2_day_mmelsm, ignore_index=True)\n",
    "    df_mmelsm['v2_day_mmelsm'] = v2_day_mmelsm\n",
    "    print(f'Participants with {sequence_length} continuous {time_period}s in v2_day_mmelsm: {len(v2_day_mmelsm['participant_id'].unique())}')\n",
    "\n",
    "\n",
    "# V1_Day\n",
    "v1_day_mmelsm = []\n",
    "sequence_length = 9\n",
    "\n",
    "for participant, df in dfs_lagged['v1_day_lag'].groupby('participant_id'):\n",
    "    result = find_largest_continuous_sequence(df, time_period, sequence_length)\n",
    "    if result is not None:\n",
    "        v1_day_mmelsm.append(result)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if v1_day_mmelsm:\n",
    "    v1_day_mmelsm = pd.concat(v1_day_mmelsm, ignore_index=True)\n",
    "    df_mmelsm['v1_day_mmelsm'] = v1_day_mmelsm\n",
    "    print(f'Participants with {sequence_length} continuous {time_period}s in v1_day_mmelsm: {len(v1_day_mmelsm['participant_id'].unique())}')\n",
    "\n",
    "\n",
    "# V1_Phq2\n",
    "v1_week_phq2_mmelsm = []\n",
    "sequence_length = 8 #4=170, 8=89\n",
    "time_period = 'week'\n",
    "\n",
    "for participant, df in dfs_lagged['v1_week_phq2_lag'].groupby('participant_id'):\n",
    "    result = find_largest_continuous_sequence(df, time_period, sequence_length)\n",
    "    if result is not None:\n",
    "        v1_week_phq2_mmelsm.append(result)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if v1_week_phq2_mmelsm:\n",
    "    v1_week_phq2_mmelsm = pd.concat(v1_week_phq2_mmelsm, ignore_index=True)\n",
    "    df_mmelsm['v1_week_phq2_mmelsm'] = v1_week_phq2_mmelsm\n",
    "    print(f'Participants with {sequence_length} continuous {time_period}s in v1_week_phq2_mmelsm: {len(v1_week_phq2_mmelsm['participant_id'].unique())}')\n",
    "\n",
    "\n",
    "# V2_Phq2\n",
    "v2_week_phq2_mmelsm = []\n",
    "sequence_length = 4\n",
    "time_period = 'week'\n",
    "\n",
    "for participant, df in dfs_lagged['v2_week_phq2_lag'].groupby('participant_id'):\n",
    "    result = find_largest_continuous_sequence(df, time_period, sequence_length)\n",
    "    if result is not None:\n",
    "        v2_week_phq2_mmelsm.append(result)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if v2_week_phq2_mmelsm:\n",
    "    v2_week_phq2_mmelsm = pd.concat(v2_week_phq2_mmelsm, ignore_index=True)\n",
    "    df_mmelsm['v2_week_phq2_mmelsm'] = v2_week_phq2_mmelsm\n",
    "    print(f'Participants with {sequence_length} continuous {time_period}s in v2_week_phq2_mmelsm: {len(v2_week_phq2_mmelsm['participant_id'].unique())}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# V1_Phq9 \n",
    "v1_week_phq9_mmelsm = []\n",
    "sequence_length = 4\n",
    "time_period = 'week'\n",
    "\n",
    "for participant, df in dfs_lagged['v1_week_phq9_lag'].groupby('participant_id'):\n",
    "    result = find_largest_continuous_sequence(df, time_period, sequence_length)\n",
    "    if result is not None:\n",
    "        v1_week_phq9_mmelsm.append(result)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if v1_week_phq9_mmelsm:\n",
    "    v1_week_phq9_mmelsm = pd.concat(v1_week_phq9_mmelsm, ignore_index=True)\n",
    "    df_mmelsm['v1_week_phq9_mmelsm'] = v1_week_phq9_mmelsm\n",
    "    print(f'Participants with {sequence_length} continuous {time_period}s in v1_week_phq9_mmelsm: {len(v1_week_phq9_mmelsm['participant_id'].unique())}')\n",
    "\n",
    "\n",
    "\n",
    "# V2_Phq9 \n",
    "v2_week_phq9_mmelsm = []\n",
    "sequence_length = 3\n",
    "time_period = 'week'\n",
    "\n",
    "for participant, df in dfs_lagged['v2_week_phq9_lag'].groupby('participant_id'):\n",
    "    result = find_largest_continuous_sequence(df, time_period, sequence_length)\n",
    "    if result is not None:\n",
    "        v2_week_phq9_mmelsm.append(result)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if v2_week_phq9_mmelsm:\n",
    "    v2_week_phq9_mmelsm = pd.concat(v2_week_phq9_mmelsm, ignore_index=True)\n",
    "    df_mmelsm['v2_week_phq9_mmelsm'] = v2_week_phq9_mmelsm\n",
    "    print(f'Participants with {sequence_length} continuous {time_period}s in v2_week_phq9_mmelsm: {len(v2_week_phq9_mmelsm['participant_id'].unique())}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for name, df in df_mmelsm.items():\n",
    "    df.to_csv(os.path.join(brighten_dir, f'{name}.csv'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
